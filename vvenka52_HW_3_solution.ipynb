{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b5d28fc",
   "metadata": {},
   "source": [
    "### Problem 1 (50 points) \n",
    "\n",
    "Vapor-liquid equilibria data are correlated using two adjustable parameters $A_{12}$ and $A_{21}$ per binary\n",
    "mixture. For low pressures, the equilibrium relation can be formulated as:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p = & x_1\\exp\\left(A_{12}\\left(\\frac{A_{21}x_2}{A_{12}x_1+A_{21}x_2}\\right)^2\\right)p_{water}^{sat}\\\\\n",
    "& + x_2\\exp\\left(A_{21}\\left(\\frac{A_{12}x_1}{A_{12}x_1+A_{21}x_2}\\right)^2\\right)p_{1,4 dioxane}^{sat}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Here the saturation pressures are given by the Antoine equation\n",
    "\n",
    "$$\n",
    "\\log_{10}(p^{sat}) = a_1 - \\frac{a_2}{T + a_3},\n",
    "$$\n",
    "\n",
    "where $T = 20$($^{\\circ}{\\rm C}$) and $a_{1,2,3}$ for a water - 1,4 dioxane\n",
    "system is given below.\n",
    "\n",
    "|             | $a_1$     | $a_2$      | $a_3$     |\n",
    "|:------------|:--------|:---------|:--------|\n",
    "| Water       | 8.07131 | 1730.63  | 233.426 |\n",
    "| 1,4 dioxane | 7.43155 | 1554.679 | 240.337 |\n",
    "\n",
    "\n",
    "The following table lists the measured data. Recall that in a binary system $x_1 + x_2 = 1$.\n",
    "\n",
    "|$x_1$ | 0.0 | 0.1 | 0.2 | 0.3 | 0.4 | 0.5 | 0.6 | 0.7 | 0.8 | 0.9 | 1.0 |\n",
    "|:-----|:--------|:---------|:--------|:-----|:-----|:-----|:-----|:-----|:-----|:-----|:-----|\n",
    "|$p$| 28.1 | 34.4 | 36.7 | 36.9 | 36.8 | 36.7 | 36.5 | 35.4 | 32.9 | 27.7 | 17.5 |\n",
    "\n",
    "Estimate $A_{12}$ and $A_{21}$ using data from the above table: \n",
    "\n",
    "1. Formulate the least square problem; \n",
    "2. Since the model is nonlinear, the problem does not have an analytical solution. Therefore, solve it using the gradient descent or Newton's method implemented in HW1; \n",
    "3. Compare your optimized model with the data. Does your model fit well with the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaad1d0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-48b05200f7b4>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-48b05200f7b4>\"\u001b[1;36m, line \u001b[1;32m10\u001b[0m\n\u001b[1;33m    cons ({'type': 'eq' : x1knob + x2knob - 1})\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "from numpy import linspace\n",
    "pstaw = 10 ** (8.07131 - (1730.60/(20 + 233.426)))\n",
    "psatd = 10 ** (7.43155 - (1554.679/(20 + 240.337)))\n",
    "x1knob = linspace(0, 1, 11)\n",
    "for i in x1knob:\n",
    "    x2knob = 1 - x1knob\n",
    "    press = lambda x: (x1knob*exp(x[0]*((x[0]*x2knob)/(x[0]*x1knob + x[1]*x2knob)) ** 2) * psatw + \n",
    "                      (x2knob*exp(x[1]*((x[0]*x1knob)/(x[0]*x1knob + x[1]*x2knob)) ** 2)* psatd))\n",
    "    cons ({'type': 'eq' : x1knob + x2knob - 1})\n",
    "    res = minimize(press, (1, 1), method='SLSQP',bounds=None, constraints=cons)\n",
    "    res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78d089ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-7be26ffabf0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# TODO: change the termination criterion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1knob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx1knob\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx2knob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx1knob\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx2knob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mpsatw\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx2knob\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx1knob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx1knob\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx2knob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m \u001b[0mpsatd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscipy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    478\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 480\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    481\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "# A simple example of using PyTorch for gradient descent\n",
    "import numpy\n",
    "import torch as t\n",
    "from scipy import exp as exp\n",
    "from scipy import gradient\n",
    "from torch.autograd import Variable\n",
    "\n",
    "psatw = 10 ** (8.07131 - (1730.60/(20 + 233.426)))\n",
    "psatd = 10 ** (7.43155 - (1554.679/(20 + 240.337)))\n",
    "x1knob = numpy.array([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "x2knob = 1 - x1knob\n",
    "p = numpy.array([28.1, 34.4, 36.7, 36.9, 36.8,36.7, 36.5, 35.4, 32.9, 27.7, 17.5])\n",
    "x = Variable(t.tensor([1.0, 0.0]), requires_grad=True)\n",
    "\n",
    "# Fix the step size\n",
    "a = 0.001\n",
    "\n",
    "# Start gradient descent\n",
    "for i in range(1000):  # TODO: change the termination criterion\n",
    "    for i in range(0, len(x1knob)):\n",
    "        loss = (x1knob*exp(x[0]*((x[0]*x2knob)/(x[0]*x1knob + x[1]*x2knob)) ** 2) * psatw + (x2knob*exp(x[1]*((x[0]*x1knob)/(x[0]*x1knob + x[1]*x2knob)) ** 2)* psatd) - p[i]) ** 2\n",
    "        loss.backward()\n",
    "    x.gradient.scipy()\n",
    "    # no_grad() specifies that the operations within this context are not part of the computational graph, i.e., we don't need the gradient descent algorithm itself to be differentiable with respect to x\n",
    "    with t.no_grad():\n",
    "        x -= a * x.gradient\n",
    "        \n",
    "        # need to clear the gradient at every step, or otherwise it will accumulate...\n",
    "        x.gradient.zero_()\n",
    "        \n",
    "print(x.data.numpy())\n",
    "print(loss.data.numpy())\n",
    "# Define a loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d33e9c7",
   "metadata": {},
   "source": [
    "### Problem 2 (50 points) \n",
    "\n",
    "Solve the following problem using Bayesian Optimization:\n",
    "$$\n",
    "    \\min_{x_1, x_2} \\quad \\left(4-2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2,\n",
    "$$\n",
    "for $x_1 \\in [-3,3]$ and $x_2 \\in [-2,2]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac0137ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     x     |     y     |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.4252  \u001b[0m | \u001b[0m-0.4979  \u001b[0m | \u001b[0m 0.8813  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.004363\u001b[0m | \u001b[0m-2.999   \u001b[0m | \u001b[0m-0.7907  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.3117  \u001b[0m | \u001b[0m-0.5814  \u001b[0m | \u001b[0m 1.057   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.3422  \u001b[0m | \u001b[0m-0.3102  \u001b[0m | \u001b[0m 0.4876  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.04594 \u001b[0m | \u001b[0m-2.104   \u001b[0m | \u001b[0m 0.5152  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.3345  \u001b[0m | \u001b[0m-0.3142  \u001b[0m | \u001b[0m 0.4566  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 0.1121  \u001b[0m | \u001b[0m 1.061   \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m 0.7885  \u001b[0m | \u001b[95m-0.84    \u001b[0m | \u001b[95m 0.5745  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7084  \u001b[0m | \u001b[0m-1.071   \u001b[0m | \u001b[0m 0.3112  \u001b[0m |\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m 8.34    \u001b[0m | \u001b[95m-1.183   \u001b[0m | \u001b[95m 0.7247  \u001b[0m |\n",
      "| \u001b[95m 11      \u001b[0m | \u001b[95m 8.948   \u001b[0m | \u001b[95m-1.295   \u001b[0m | \u001b[95m 0.8243  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.04111 \u001b[0m | \u001b[0m-2.109   \u001b[0m | \u001b[0m-0.3733  \u001b[0m |\n",
      "=================================================\n",
      "{'target': 8.947749691096538, 'params': {'x': -1.294970077603155, 'y': 0.8243099161829229}}\n",
      "Iteration 0: \n",
      "\t{'target': 0.4251709708452254, 'params': {'x': -0.4978679717845562, 'y': 0.8812979737686324}}\n",
      "Iteration 1: \n",
      "\t{'target': 0.004362821965838803, 'params': {'x': -2.9993137510959307, 'y': -0.7906697094726409}}\n",
      "Iteration 2: \n",
      "\t{'target': 0.31170664117554986, 'params': {'x': -0.5814104453881583, 'y': 1.0565648045688776}}\n",
      "Iteration 3: \n",
      "\t{'target': 0.34221163047253483, 'params': {'x': -0.31017346177570987, 'y': 0.4875763756575679}}\n",
      "Iteration 4: \n",
      "\t{'target': 0.04593840070395938, 'params': {'x': -2.1041597209576226, 'y': 0.5152470560110505}}\n",
      "Iteration 5: \n",
      "\t{'target': 0.33448503420384046, 'params': {'x': -0.31415510372944944, 'y': 0.4565500689076756}}\n",
      "Iteration 6: \n",
      "\t{'target': 0.21487694392805348, 'params': {'x': 0.11213357537937557, 'y': 1.0605477636293157}}\n",
      "Iteration 7: \n",
      "\t{'target': 0.7885057280778138, 'params': {'x': -0.8400320040438104, 'y': 0.5744853812056648}}\n",
      "Iteration 8: \n",
      "\t{'target': 0.7083902968884568, 'params': {'x': -1.0707387296570503, 'y': 0.31119271267831883}}\n",
      "Iteration 9: \n",
      "\t{'target': 8.339805689028191, 'params': {'x': -1.1830715745021658, 'y': 0.7246708081514335}}\n",
      "Iteration 10: \n",
      "\t{'target': 8.947749691096538, 'params': {'x': -1.294970077603155, 'y': 0.8243099161829229}}\n",
      "Iteration 11: \n",
      "\t{'target': 0.04111234971276973, 'params': {'x': -2.109330931301038, 'y': -0.3732652702230812}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def black_func(x, y):\n",
    "     return 1/(4 - 2.1 * x ** 2 + ((x ** 4) / 3) * x ** 2 + x * y + (-4 + 4 * y ** 2) * y ** 2)\n",
    "    \n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "bounds = {'x': (-3,3), 'y': (-2,2)}\n",
    "\n",
    "optim = BayesianOptimization(f=black_func, pbounds=bounds, random_state=1)\n",
    "optim.maximize(init_points=2,n_iter=10)\n",
    "print(optim.max)\n",
    "\n",
    "for i, res in enumerate(optim.res):\n",
    "    print(\"Iteration {}: \\n\\t{}\".format(i, res))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
